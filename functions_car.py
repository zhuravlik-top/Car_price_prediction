
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import numpy as np
import phik
from phik import resources
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score, precision_score, roc_auc_score
from sklearn.ensemble import GradientBoostingClassifier
from catboost import CatBoostClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
import random
from sklearn.model_selection import cross_validate
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import make_scorer, mean_absolute_error
from sklearn.model_selection import GridSearchCV
from category_encoders import TargetEncoder
from sklearn.preprocessing import FunctionTransformer
from IPython.display import display, Markdown
from sklearn.compose import TransformedTargetRegressor
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.base import clone


def preprocess_features_before_pipeline(df):
    """
    ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð¼Ð¾Ð¶Ð½Ð¾ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ð”Ðž Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ð¸ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸.
    ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ñ†ÐµÐ»ÐµÐ²ÑƒÑŽ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ, Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ Ð´Ð»Ñ CV.
    """
    df = df.copy()

    # 1. ÐžÑ‡Ð¸ÑÑ‚ÐºÐ°
    if "ID" in df.columns:
        df = df.drop_duplicates().drop(columns=["ID"], errors="ignore")

    # 2. Mileage Ð² Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ Ñ‚Ðº Ð¾Ð½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‡Ð¸ÑÐ»Ð°
    if "Mileage" in df.columns:
        df["Mileage"] = (
            df["Mileage"]
            .str.replace(" km", "", regex=False)
            .str.replace(" ", "", regex=False)
            .astype(float)
        )

    # 3. Levy Ð² Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ Ñ‚Ðº ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‡Ð¸ÑÐ»Ð°
    if "Levy" in df.columns:
        df["Levy"] = df["Levy"].replace("-", "0").astype(float)
    # 4. Dooors Ð² Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ 
    def convert_doors(val):
        val = str(val).strip()
        if "-" in val:
            try:
                return int(val.split("-")[0])
            except:
                return np.nan
        if val.startswith(">"):
            try:
                return int(val[1:]) + 1
            except:
                return np.nan
        try:
            return int(val)
        except:
            return np.nan

    if "Doors" in df.columns:
        df["Doors"] = df["Doors"].apply(convert_doors)


    if "Engine volume" in df.columns:
        df["is_turbo"] = df["Engine volume"].str.contains("Turbo", case=False, na=False).astype(int)
        df["engine_size"] = df["Engine volume"].str.extract(r"(\d+\.?\d*)").astype(float)
        df = df.drop(columns=["Engine volume"])


    if "Leather interior" in df.columns:
        df["Leather interior"] = df["Leather interior"].map({"Yes": 1, "No": 0})

    return df


def prepare_regression_data(df, seed=42, test_size=0.2, verbose=True):
    """
    ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¸.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ X, y, train/test split Ð¸ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ DataFrame Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð².
    """
    print("ðŸ”¥ prepare_regression_data() called â€” CLEAN 8-VARIANT version")

    df = df.copy()

    # 1. ÐžÑ‡Ð¸ÑÑ‚ÐºÐ°
    if "ID" in df.columns:
        df = df.drop_duplicates().drop(columns=["ID"], errors="ignore")

    if "Mileage" in df.columns:
        df["Mileage"] = (
            df["Mileage"]
            .str.replace(" km", "", regex=False)
            .str.replace(" ", "", regex=False)
            .astype(int)
        )

    if "Levy" in df.columns:
        df["Levy"] = df["Levy"].replace("-", "0").astype(int)

    # 2. Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ
    y = df["Price"]
    X = df.drop(columns=["Price"])

    # 3. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Doors
    def convert_doors(val):
        val = str(val).strip()
        if "-" in val:
            try:
                return int(val.split("-")[0])
            except:
                return np.nan
        if val.startswith(">"):
            try:
                return int(val[1:]) + 1
            except:
                return np.nan
        try:
            return int(val)
        except:
            return np.nan

    if "Doors" in X.columns:
        X["Doors"] = X["Doors"].apply(convert_doors)

    # 4. Engine volume
    if "Engine volume" in X.columns:
        X["is_turbo"] = X["Engine volume"].str.contains("Turbo", case=False, na=False).astype(int)
        X["engine_size"] = X["Engine volume"].str.extract(r"(\d+\.?\d*)").astype(float)
        X = X.drop(columns=["Engine volume"])

    # 5. Leather interior
    if "Leather interior" in X.columns:
        X["Leather interior"] = X["Leather interior"].map({"Yes": 1, "No": 0})

    # 6. Train/Test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=seed
    )
    y_train_log = np.log1p(y_train)

    # 7. Target Encoding
    cat_target = ["Manufacturer", "Model", "Color"]
    cat_onehot = ["Category", "Fuel type", "Gear box type", "Drive wheels", "Wheel"]

    target_cols = [c for c in cat_target if c in X_train.columns]
    if target_cols:
        te = TargetEncoder(
            handle_unknown="value",
            handle_missing="value",
            min_samples_leaf=5,
            smoothing=10
        )
        X_train[target_cols] = te.fit_transform(X_train[target_cols], y_train_log)
        X_test[target_cols] = te.transform(X_test[target_cols])

        global_mean = y_train_log.mean()
        X_train[target_cols] = X_train[target_cols].fillna(global_mean)
        X_test[target_cols] = X_test[target_cols].fillna(global_mean)

    # 8. ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            ("one_hot", Pipeline([
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
            ]), [col for col in cat_onehot if col in X_train.columns]),
            ("num", SimpleImputer(strategy="median"), [
                col for col in X_train.columns if col not in cat_onehot
            ]),
        ],
        remainder="drop"
    )

    preprocessor.fit(X_train)
    feature_names = preprocessor.get_feature_names_out(input_features=X_train.columns)

    X_train_pre = pd.DataFrame(preprocessor.transform(X_train),
                               index=X_train.index,
                               columns=feature_names)
    X_test_pre = pd.DataFrame(preprocessor.transform(X_test),
                              index=X_test.index,
                              columns=feature_names)

    # 9. Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð¼Ð¿ÑŒÑŽÑ‚Ð°Ñ†Ð¸Ñ
    imputer = SimpleImputer(strategy="most_frequent")
    X_train_preprocessed = pd.DataFrame(imputer.fit_transform(X_train_pre),
                                        index=X_train.index,
                                        columns=feature_names)
    X_test_preprocessed = pd.DataFrame(imputer.transform(X_test_pre),
                                       index=X_test.index,
                                       columns=feature_names)

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°
    assert not X_train_preprocessed.isna().any().any(), "NaN Ð² X_train_preprocessed!"
    assert not X_test_preprocessed.isna().any().any(), "NaN Ð² X_test_preprocessed!"

    # 10. Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
    if verbose:
        display(Markdown(
            f"âœ… **Preprocessing complete.**  \n"
            f"Train samples: **{len(X_train_preprocessed)}**, "
            f"Test samples: **{len(X_test_preprocessed)}**  \n"
            f"Features: **{len(feature_names)}**"
        ))
    print("âž¡ RETURN executed with 8 values")

    return (
        X, y,
        X_train, y_train,
        X_test, y_test,
        X_train_preprocessed,
        X_test_preprocessed
    )




def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true != 0
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

def symmetric_mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))




def evaluate_models_cv_regression_safe_new(
    models,
    preprocessor,
    X,
    y,
    cv=5,
    seed=None,
    log=False
):
    """
    ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¼ preprocessor.
    Ð›ÑŽÐ±Ð¾Ð¹ feature engineering Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÑÐ´ÐµÐ»Ð°Ð½ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ preprocessor.
    
    Ð­Ñ‚Ð° Ð²ÐµÑ€ÑÐ¸Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ð¾Ð´ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð² X.
    """
    
    all_metrics = {}

    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð¸Ð· X
    X_cols = set(X.columns)

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¿Ð¸ÑŽ preprocessor, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¼ÐµÐ½ÑÑ‚ÑŒ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»
    preprocessor_safe = clone(preprocessor)

    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ñ‹ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ColumnTransformer
    if isinstance(preprocessor_safe, ColumnTransformer):
        new_transformers = []
        for name, transformer, cols in preprocessor_safe.transformers:
            # Ð‘ÐµÑ€ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ ÐµÑÑ‚ÑŒ Ð² X
            cols_filtered = [c for c in cols if c in X_cols]
            if len(cols_filtered) > 0:
                new_transformers.append((name, transformer, cols_filtered))
        preprocessor_safe.transformers = new_transformers

    for name, base_model in models:
        print(f"\n{'='*60}\nÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {name}\n{'='*60}")

        if seed is not None and hasattr(base_model, "random_state"):
            base_model.set_params(random_state=seed)

        # Ð›Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ†ÐµÐ»Ð¸
        model = (
            TransformedTargetRegressor(
                regressor=base_model,
                func=np.log1p,
                inverse_func=np.expm1
            ) if log else base_model
        )

        # ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½: preprocessor + Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        pipeline = Pipeline([
            ("preprocessor", preprocessor_safe),
            ("model", model)
        ])

        # ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        y_pred = cross_val_predict(pipeline, X, y, cv=cv, n_jobs=-1)

        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
        MAE = mean_absolute_error(y, y_pred)
        MSE = mean_squared_error(y, y_pred)
        RMSE = np.sqrt(MSE)
        R2 = r2_score(y, y_pred)
        #MAPE = np.mean(np.abs((y - y_pred) / np.maximum(y, 1e-8))) * 100
        SMAPE = 100 * np.mean(2 * np.abs(y - y_pred) / (np.abs(y) + np.abs(y_pred) + 1e-8))

        all_metrics[name] = {
            "MAE": MAE,
            "MSE": MSE,
            "RMSE": RMSE,
            "R2": R2,
            #"MAPE": MAPE,
            "SMAPE": SMAPE
        }

        print(f"R2:    {R2:.4f}")
        print(f"MSE:   {MSE:.2f}")
        print(f"MAE:   {MAE:.2f}")
        print(f"RMSE:  {RMSE:.2f}")
        #print(f"MAPE:  {MAPE:.2f}%")
        print(f"SMAPE: {SMAPE:.2f}%")

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
    df_results = pd.DataFrame(all_metrics).T
    df_results = df_results[["MAE", "MSE", "RMSE", "R2","SMAPE"]].sort_values(by="R2", ascending=False)

    print("\n=== Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº (ÑƒÑÑ€ÐµÐ´Ð½Ñ‘Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ CV) ===")
    print(df_results.to_string(float_format="%.4f"))

    return df_results




def compare_regression_metrics(df1, df2, name1="Variant 1", name2="Variant 2", plot=True):
    """
    Ð¡Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ð´Ð²ÑƒÐ¼Ñ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°Ð¼Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ).

    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
        df1, df2: pd.DataFrame Ñ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ð¼Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ°Ð¼Ð¸ (Ð¼Ð¾Ð´ÐµÐ»Ð¸) Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
        name1, name2: Ð¸Ð¼ÐµÐ½Ð° Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð² (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð² Ð¿Ð¾Ð´Ð¿Ð¸ÑÑÑ…)
        plot: ÐµÑÐ»Ð¸ True â€” Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ñƒ Ð¿Ð¾ R2 Ð¸ MAPE

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
        diff_df â€” Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ñ Ð´ÐµÐ»ÑŒÑ‚Ð°Ð¼Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº (df2 - df1)
    """
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
    if not all(df1.index == df2.index):
        raise ValueError("ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð² df1 Ð¸ df2 Ð´Ð¾Ð»Ð¶Ð½Ñ‹ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ð¿Ð¾ Ð¿Ð¾Ñ€ÑÐ´ÐºÑƒ Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑŽ")

    # Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
    common_cols = df1.columns.intersection(df2.columns)
    if len(common_cols) == 0:
        raise ValueError("ÐÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¼ÐµÐ¶Ð´Ñƒ df1 Ð¸ df2")

    # Ð Ð°Ð·Ð½Ð¸Ñ†Ð°
    diff = df2[common_cols] - df1[common_cols]
    diff.index.name = "Model"
    diff = diff.rename(columns=lambda x: f"Î”{x} ({name2}-{name1})")

    print(f"\n=== ðŸ“Š Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº: {name2} Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² {name1} ===")
    print(diff.to_string(float_format="%.4f"))

    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ð¹
    better_higher = ["R2", "R2_CV"]
    better_lower = ["MSE", "RMSE", "MAE", "SMAPE"]

    trends = []
    for model in diff.index:
        notes = []
        for col in diff.columns:
            base = col.replace(f"Î”", "").split(" ")[0]
            val = diff.loc[model, col]
            if base in better_higher:
                notes.append("â†‘" if val > 0 else "â†“")
            elif base in better_lower:
                notes.append("â†‘" if val < 0 else "â†“")
        trends.append(" ".join(notes))
    diff["Trend"] = trends

    # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ (Ð¿Ð¾ R2 Ð¸ MAPE, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
    if plot:
        metrics_to_plot = [m for m in ["R2", "MAPE"] if any(col.startswith(f"Î”{m}") for col in diff.columns)]
        if metrics_to_plot:
            fig, axes = plt.subplots(1, len(metrics_to_plot), figsize=(6 * len(metrics_to_plot), 4))
            if len(metrics_to_plot) == 1:
                axes = [axes]
            for i, metric in enumerate(metrics_to_plot):
                col = [c for c in diff.columns if c.startswith(f"Î”{metric}")][0]
                diff[col].plot(kind='bar', ax=axes[i], color='steelblue', edgecolor='black')
                axes[i].axhline(0, color='black', linewidth=1)
                axes[i].set_title(f"{metric}: Î”({name2}-{name1})")
                axes[i].set_ylabel("Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ")
                axes[i].set_xlabel("ÐœÐ¾Ð´ÐµÐ»ÑŒ")
            plt.tight_layout()
            plt.show()

    return diff

