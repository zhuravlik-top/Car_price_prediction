Предсказание цены автомобилей  

# 1. EDA
   
# 1.1. Первичный анализ 

Датасет содержит 19 237 записей и 18 признаков, описывающих характеристики автомобилей, включая числовые и категориальные данные. После удаления 313 дубликатов осталось 18 924 уникальные записи. 

Некоторые признаки требовали предобработки: 

В колонке Levy встречались пропуски, обозначенные символом -. Они были заменены на 0 и преобразованы в числовой тип. 

Признак Mileage содержал строки вида "186005 km", которые были очищены и приведены к целым числам. 

Признак ID удалён как неинформативный для предсказания. 

Проверка на отрицательные значения для Price, Airbags, Cylinders показала их отсутствие. 

# 1.2. Преобразование признаков 

Doors содержал значения вроде 04-May, 02-Mar, >5; с помощью пользовательской функции все значения переведены в числовой формат (2, 4, 6 дверей). 

Из признака Engine volume выделены два новых признака для корректной обработки: 

engine_volume — числовой объём двигателя 

is_turbo — бинарный индикатор турбонаддува 

Leather interior преобразован из категориального (Yes/No) в бинарный (1/0). 

 

# 1.3. Распределение признаков и корреляционный анализ 

Числовые признаки (Price, Levy, Mileage, Prod. year, Cylinders, Airbags) имеют асимметричное распределение с длинными хвостами. 

Среди категориальных переменных наибольшее количество уникальных значений имеет Model (~1590), что указывает на высокую дисперсию внутри класса. 

Большинство автомобилей имеют левый руль (≈92%), топливо Petrol (≈52%), тип кузова Jeep или Sedan. 

Для смешанных типов данных использовалась метрика Phik, учитывающая числовые и категориальные признаки. Наиболее коррелирующий с другими признак — Model. 

 

# 1.4. Подготовка данных к моделированию 

Целевая переменная Price не трансформировалась на этом этапе. 

Категориальные признаки кодировались: 

Target Encoding для признаков с большим числом категорий (Manufacturer, Model, Color) 

One-Hot Encoding для признаков с ограниченным числом категорий (Category, Fuel type, Gear box type, Drive wheels, Wheel) 

Все преобразования собраны в Pipeline с использованием ColumnTransformer для корректного разделения обучения и валидации. 

 

# 2. Baseline моделей 

# 2.1. Цель 

Построение базовых моделей для предсказания цены автомобиля на исходных признаках, чтобы определить минимальный уровень качества и выявить проблемные моменты. 

 

# 2.2. Используемые модели 

Модель 

Основные параметры 

Linear Regression 
по умолчанию 

Random Forest Regressor 
n_estimators=100, random_state=42 

 

Gradient Boosting Regressor 
random_state=42 

 

# 2.3. Результаты baseline 

Модель             MAE ↓        MSE ↓       R² ↑ 

Linear Regression 13 139     5.42×10⁸       -0.57 

Random Forest Regressor 
5 776 
2.99×10⁹ 
-7.63 

Gradient Boosting Regressor 
13 895 
3.70×10¹⁰ 
-106.05 

Вывод: отрицательные значения R² показывают, что модели не уловили структуру зависимостей между признаками и ценой на исходных данных, плохие показатели по всем метрикам 

 

# 3. Feature Engineering и тюнинг гиперпараметров

# 3.1. Генерация новых признаков и их эффективность

Примененные преобразования:

car_age - возраст автомобиля (2025 − год производства)

mileage_per_year - средний пробег в год

Mileage_log - логарифмированный пробег

Levy_log - логарифмированный налог

volume_per_cyl - объем двигателя на цилиндр

mileage_group - категоризация пробега

Анализ эффективности преобразований:


Лог-трансформация целевой переменной	 Высокая эффективность	МАЕ улучшила результат на 4912 (RandomForest)	Стабилизировало распределение, уменьшило влияние выбросов

Фильтрация выбросов (99 перцентиль)	 Высокая эффективность	МАЕ улучшила результат на 2282 (RandomForest)	Убрало экстремальные значения, мешающие обучению

Новые признаки (car_age, mileage_per_year)	 Низкая эффективность	Незначительное изменение МАЕ	

Лог-признаки (Mileage_log, Levy_log)	 Низкая эффективность	Незначительное изменение МАЕ	

Количественные результаты улучшений:

python
 Базовые результаты (до улучшений)
results_baseline = {
    'RandomForest': {'MAE': 11463, 'R2': -1.116},
    'GradientBoosting': {'MAE': 13293, 'R2': -0.679}, 
    'LinearRegression': {'MAE': 15053, 'R2': -0.008}
}


После лог-трансформации + фильтрации выбросов
results_improved = {
    'RandomForest': {'MAE': 4268, 'R2': 0.709},
    'GradientBoosting': {'MAE': 6569, 'R2': 0.449},
    'LinearRegression': {'MAE': 8462, 'R2': 0.200}
}
Сводка по улучшениям:

RandomForest: MAE улучшен на 62.8% (с 11463 до 4268)

R²: с отрицательного (-1.116) до 0.709 - модель объясняет 71% дисперсии

Основной вклад: лог-трансформация цели (60%) + фильтрация выбросов (40%)

# 3.2. Предобработка и трансформация признаков
Эффективные преобразования:

Логарифмирование целевой переменной - критически важно для данных с heavy-tailed распределением

 Фильтрация по 99-му перцентилю - убрало 1% экстремальных значений


Неэффективные преобразования:

 Дополнительная нормализация отдельных признаков (Mileage, Levy)

Создание производных признаков без значимого прироста

# 3.3. Обучение моделей и кросс-валидация
Финальные результаты после всех улучшений:

Модель	MAE	MSE	RMSE	R²	SMAPE
RandomForest	4,268	62,749,592	7,921	0.709	37.69%
GradientBoosting	6,569	118,951,690	10,906	0.449	59.52%
LinearRegression	8,462	172,692,720	13,141	0.200	71.82%
Ключевая метрика: MAE = 4,268 (лучшая модель - RandomForest)

# 3.4. Подбор гиперпараметров
Метод тюнинга: GridSearchCV с 5-кратной кросс-валидацией

Параметры для RandomForest:

python
param_grid = {
    "n_estimators": [100, 200, 500],
    "max_depth": [None, 10, 20, 30], 
    "min_samples_split": [2, 5, 10]
}
Результаты тюнинга:

Лучшие параметры: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2}

MAE до тюнинга: 4,268

MAE после тюнинга: 4,252

Прирост: 0.3% (незначительное улучшение)

Объяснение: RandomForest оказался достаточно устойчив к гиперпараметрам, основные улучшения были достигнуты за счет предобработки данных.

# 3.5. Итоговые выводы 

Основной выигрыш получен от правильной предобработки (лог-трансформация + фильтрация выбросов)

Feature engineering дал минимальный прирост - исходные признаки были достаточно информативны

RandomForest показал наилучшие результаты благодаря устойчивости к шуму и нелинейностям

 
